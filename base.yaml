seed: 42
device: cuda
dataset:
  name: iwslt2017
  seq_len: 64
training:
  batch_size: 32
  lr: 0.0003
  weight_decay: 0.05
  epochs: 30
  grad_clip: 1.0
model:
  vocab_size: null  
  d_model: 128
  n_heads: 4
  d_ff: 512
  n_layers: 2
  dropout: 0.1
logging:
  save_dir: results
  print_every: 100
